kube-prometheus-stack:
  alertmanager:
    config:
      route:
        receiver: slack
        routes:
          - matchers:
              - alertname = "Watchdog"
            receiver: 'statuscake'
            repeat_interval: 10m
      receivers:
        - name: slack
          slack_configs:
          - api_url_file: /etc/alertmanager/secrets/alertmanager-slack-api-url/api-url
            channel: "#cluster-rke2-notifications"
            send_resolved: true
            text: |
              {{ len .Alerts }} alerts for namespace "{{ .CommonLabels.namespace }}"
              {{ range $i, $alert := .Alerts }}
              *Alert #{{$i}}* | {{ .Labels.alertname }} | {{ .Status }} | {{ .StartsAt }}
              {{ range $k, $v := .Labels }}  - {{$k}}: {{$v}}
              {{ end }}{{ range $k, $v := .Annotations }}  - {{$k}}: {{$v}}
              {{ end }}<{{ .GeneratorURL }}|View in Prometheus>
              {{ end }}
        - name: statuscake
          webhook_configs:
            - url_file: /etc/alertmanager/secrets/statuscake-webhook-url/url
              send_resolved: false
    alertmanagerSpec:
      externalUrl: "https://alertmanager.~iac:rke2_catchall_hostname~"
      secrets:
        - alertmanager-slack-api-url
        - statuscake-webhook-url
      resources:
        requests:
          cpu: 400m
          memory: 300Mi
        limits:
          memory: 500Mi
      storage:
        volumeClaimTemplate:
          spec:
            storageClassName: "local-storage"
            accessModes:
              - ReadWriteMany
            resources:
              requests:
                storage: 500Gi
            selector:
              matchLabels:
                app.kubernetes.io/name: monitoring-alertmanager
                app.kubernetes.io/managed-by: terraform-hasadna-rke2-storage

  grafana:
    resources:
      requests:
        cpu: 500m
        memory: 400Mi
      limits:
        memory: 800Mi
    persistence:
      enabled: true
      existingClaim: "grafana"
    admin:
      existingSecret: "grafana-admin-password"
    additionalDataSources:
      - name: "Loki"
        type: loki
        url: "http://logging-loki-gateway.logging"
        jsonData:
          maxLines: 1000
          timeout: 60
    "grafana.ini":
      explore:
        enabled: true
        allow_viewer_explore: true

  prometheusOperator:
    namespaces:
      releaseNamespace: true
      additional:
        - "rook-ceph"
    resources:
      requests:
        cpu: 200m
        memory: 200Mi
      limits:
        memory: 400Mi

  prometheus:
    prometheusSpec:
      externalUrl: "https://prometheus.~iac:rke2_catchall_hostname~"
      serviceMonitorSelectorNilUsesHelmValues: false
      podMonitorSelectorNilUsesHelmValues: false
      retention: 7d
      resources:
        requests:
          cpu: 400m
          memory: 600Mi
        limits:
          memory: 1200Mi
      storageSpec:
        volumeClaimTemplate:
          spec:
            storageClassName: "local-storage"
            accessModes:
              - ReadWriteMany
            resources:
              requests:
                storage: 500Gi
            selector:
              matchLabels:
                app.kubernetes.io/name: monitoring-prometheus
                app.kubernetes.io/managed-by: terraform-hasadna-rke2-storage

  kubeEtcd:
    enabled: false

  kubeScheduler:
    enabled: false

  kubeControllerManager:
    enabled: false

  kubeProxy:
    enabled: false

  nodeExporter:
    operatingSystems:
      aix:
        enabled: false
      darwin:
        enabled: false

  prometheus-node-exporter:
    extraArgs:
      # defaults from kube-prometheus-stack/values.yaml
      - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
      - --collector.filesystem.fs-types-exclude=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$
      # additional collectors for hasadna
      - --collector.systemd
      - --collector.mountstats
      - --collector.systemd.unit-include=ufw.service|rke2-server.service|rke2-agent.service
    tolerations:
      - effect: NoExecute
        operator: Exists
    extraHostVolumeMounts:
      - name: dbus
        hostPath: /var/run/dbus
        mountPath: /var/run/dbus
        readOnly: true
    podAnnotations:
      container.apparmor.security.beta.kubernetes.io/node-exporter: unconfined

ingresses:
  - name: alertmanager
    ssl: true
    httpauth:
      secretName: "alertmanager-http-auth"
      message: "Alertmanager Authentication Required"
    rules:
      - host: "alertmanager.~iac:rke2_catchall_hostname~"
        serviceName: alertmanager-operated
        servicePort: 9093
  - name: grafana
    ssl: true
    rules:
      - host: "grafana.~iac:rke2_catchall_hostname~"
        serviceName: monitoring-grafana
        servicePort: 80
  - name: prometheus
    ssl: true
    httpauth:
      secretName: "prometheus-http-auth"
      message: "Prometheus Authentication Required"
    rules:
      - host: "prometheus.~iac:rke2_catchall_hostname~"
        serviceName: prometheus-operated
        servicePort: 9090

secrets:
  - name: alertmanager-http-auth
    data:
      # htpasswd -nb username password
      auth: "~vault:Projects/k8s/alertmanager:httpauth~"
  - name: prometheus-http-auth
    data:
      # htpasswd -nb username password
      auth: "~vault:Projects/k8s/prometheus:httpauth~"
  - name: grafana-admin-password
    data:
      admin-user: "~vault:Projects/k8s/grafana-admin:admin-user~"
      admin-password: "~vault:Projects/k8s/grafana-admin:admin-password~"
  - name: alertmanager-slack-api-url
    data:
      api-url: "~vault:Projects/iac/monitoring:slack-webhook-cluster-rke2-notifications~"
  - name: statuscake-webhook-url
    data:
      url: "~vault:Projects/iac/monitoring-statuscake-watchdog:webhook-url~"
